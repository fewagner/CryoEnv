{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7fc72d-9816-4c4e-a98d-f5ae795a1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import DecisionTransformerConfig, DecisionTransformerModel, Trainer, TrainingArguments\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4543ed84-5fe1-44bf-ae56-3e5ed4ae7343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset pandas (/users/felix.wagner/.cache/huggingface/datasets/pandas/default-6c4318920887342e/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d8472404fe4ca38853f6c5811b914d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"pandas\", data_files=\"saved_pars/transformer_dataset.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724690d-27fe-494c-ba59-3292bb6ffe48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919a8137-134b-4b82-bfa0-d7218af0f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecisionTransformerGymDataCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "    max_len: int = 20 #subsets of the episode we use for training\n",
    "    state_dim: int = 17  # size of state space\n",
    "    act_dim: int = 6  # size of action space\n",
    "    max_ep_len: int = 1000 # max episode length in the dataset\n",
    "    scale: float = 1000.0  # normalization of rewards/returns\n",
    "    state_mean: np.array = None  # to store state means\n",
    "    state_std: np.array = None  # to store state stds\n",
    "    p_sample: np.array = None  # a distribution to take account trajectory lengths\n",
    "    n_traj: int = 0 # to store the number of trajectories in the dataset\n",
    "\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.act_dim = len(dataset[0][\"actions\"][0])\n",
    "        self.state_dim = len(dataset[0][\"observations\"][0])\n",
    "        self.dataset = dataset\n",
    "        # calculate dataset stats for normalization of states\n",
    "        states = []\n",
    "        traj_lens = []\n",
    "        for obs in dataset[\"observations\"]:\n",
    "            states.extend(obs)\n",
    "            traj_lens.append(len(obs))\n",
    "        self.n_traj = len(traj_lens)\n",
    "        states = np.vstack(states)\n",
    "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "        \n",
    "        traj_lens = np.array(traj_lens)\n",
    "        self.p_sample = traj_lens / sum(traj_lens)\n",
    "\n",
    "    def _discount_cumsum(self, x, gamma):\n",
    "        discount_cumsum = np.zeros_like(x)\n",
    "        discount_cumsum[-1] = x[-1]\n",
    "        for t in reversed(range(x.shape[0] - 1)):\n",
    "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "        return discount_cumsum\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch_size = len(features)\n",
    "        # this is a bit of a hack to be able to sample of a non-uniform distribution\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(self.n_traj),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=self.p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "        # a batch of dataset features\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "        \n",
    "        for ind in batch_inds:\n",
    "            # for feature in features:\n",
    "            feature = self.dataset[int(ind)]\n",
    "            si = random.randint(0, len(feature[\"rewards\"]) - 1)\n",
    "\n",
    "            # get sequences from dataset\n",
    "            s.append(np.array(feature[\"observations\"][si : si + self.max_len]).reshape(1, -1, self.state_dim))\n",
    "            a.append(np.array(feature[\"actions\"][si : si + self.max_len]).reshape(1, -1, self.act_dim))\n",
    "            r.append(np.array(feature[\"rewards\"][si : si + self.max_len]).reshape(1, -1, 1))\n",
    "\n",
    "            d.append(np.array(feature[\"dones\"][si : si + self.max_len]).reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= self.max_ep_len] = self.max_ep_len - 1  # padding cutoff\n",
    "            rtg.append(\n",
    "                self._discount_cumsum(np.array(feature[\"rewards\"][si:]), gamma=1.0)[\n",
    "                    : s[-1].shape[1]   # TODO check the +1 removed here\n",
    "                ].reshape(1, -1, 1)\n",
    "            )\n",
    "            if rtg[-1].shape[1] < s[-1].shape[1]:\n",
    "                print(\"if true\")\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, self.state_dim)), s[-1]], axis=1)\n",
    "            s[-1] = (s[-1] - self.state_mean) / self.state_std\n",
    "            a[-1] = np.concatenate(\n",
    "                [np.ones((1, self.max_len - tlen, self.act_dim)) * -10.0, a[-1]],\n",
    "                axis=1,\n",
    "            )\n",
    "            r[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, self.max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), rtg[-1]], axis=1) / self.scale\n",
    "            timesteps[-1] = np.concatenate([np.zeros((1, self.max_len - tlen)), timesteps[-1]], axis=1)\n",
    "            mask.append(np.concatenate([np.zeros((1, self.max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).float()\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).float()\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).float()\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0))\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).float()\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).long()\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).float()\n",
    "\n",
    "        return {\n",
    "            \"states\": s,\n",
    "            \"actions\": a,\n",
    "            \"rewards\": r,\n",
    "\n",
    "            \"returns_to_go\": rtg,\n",
    "            \"timesteps\": timesteps,\n",
    "            \"attention_mask\": mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315e2ba5-0900-40c3-9068-6b09f7af72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableDT(DecisionTransformerModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        output = super().forward(**kwargs)\n",
    "        # add the DT loss\n",
    "        action_preds = output[1]\n",
    "        action_targets = kwargs[\"actions\"]\n",
    "        attention_mask = kwargs[\"attention_mask\"]\n",
    "        act_dim = action_preds.shape[2]\n",
    "        action_preds = action_preds.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        action_targets = action_targets.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        \n",
    "        loss = torch.mean((action_preds - action_targets) ** 2)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def original_forward(self, **kwargs):\n",
    "        return super().forward(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d94f85-04e7-4853-9f11-b1e31570d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DecisionTransformerGymDataCollator(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a42141-d033-4ad7-9067-c7247a2fd9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim)\n",
    "model = TrainableDT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9074864-c141-465c-b194-cebbcb332f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrainableDT.from_pretrained('output/checkpoint-23500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4cbf33-9a6d-4fb9-90c5-bdfe6c8bf3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23640' max='23640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23640/23640 49:43, Epoch 120/120]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.095200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.064800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.049300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.044200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23640, training_loss=0.03745000237337426, metrics={'train_runtime': 2984.9662, 'train_samples_per_second': 506.538, 'train_steps_per_second': 7.92, 'total_flos': 651033936000000.0, 'train_loss': 0.03745000237337426, 'epoch': 120.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=120,\n",
    "    per_device_train_batch_size=64,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=0.25,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fba797-cdc8-47fd-ae56-2506c6651c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = np.array([500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, \n",
    "                  5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, \n",
    "                  10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, \n",
    "                  15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, \n",
    "                  19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, 23500])\n",
    "\n",
    "training_loss = np.array([0.1819, 0.1334, 0.1222, 0.1123, 0.0952, 0.0768, \n",
    "                          0.0648, 0.0561, 0.0493, 0.0442, 0.0408, 0.0378, \n",
    "                          0.0351, 0.0329, 0.0314, 0.0297, 0.0285, 0.0276, \n",
    "                          0.0263, 0.0256, 0.0246, 0.0239, 0.0232, 0.0226, \n",
    "                          0.0221, 0.0214, 0.0211, 0.0205, 0.0201, 0.0197, \n",
    "                          0.0193, 0.0189, 0.0187, 0.0183, 0.0182, 0.0178, \n",
    "                          0.0176, 0.0174, 0.0172, 0.0169, 0.0167, 0.0166, \n",
    "                          0.0165, 0.0164, 0.0164, 0.0161, 0.0159])\n",
    "\n",
    "plt.plot(steps, training_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4080f-ee57-4ab7-a149-62f1a8839974",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca9e273-de2f-47c3-bb63-d8449a230cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets an action from the model using autoregressive prediction with a window of the previous 20 timesteps.\n",
    "def get_action(model, states, actions, rewards, returns_to_go, timesteps):\n",
    "    # This implementation does not condition on past rewards\n",
    "\n",
    "    states = states.reshape(1, -1, model.config.state_dim)\n",
    "    actions = actions.reshape(1, -1, model.config.act_dim)\n",
    "    returns_to_go = returns_to_go.reshape(1, -1, 1)\n",
    "    timesteps = timesteps.reshape(1, -1)\n",
    "\n",
    "    states = states[:, -model.config.max_length :]\n",
    "    actions = actions[:, -model.config.max_length :]\n",
    "    returns_to_go = returns_to_go[:, -model.config.max_length :]\n",
    "    timesteps = timesteps[:, -model.config.max_length :]\n",
    "    padding = model.config.max_length - states.shape[1]\n",
    "    # pad all tokens to sequence length\n",
    "    attention_mask = torch.cat([torch.zeros(padding), torch.ones(states.shape[1])])\n",
    "    attention_mask = attention_mask.to(dtype=torch.long).reshape(1, -1)\n",
    "    states = torch.cat([torch.zeros((1, padding, model.config.state_dim)), states], dim=1).float()\n",
    "    actions = torch.cat([torch.zeros((1, padding, model.config.act_dim)), actions], dim=1).float()\n",
    "    returns_to_go = torch.cat([torch.zeros((1, padding, 1)), returns_to_go], dim=1).float()\n",
    "    timesteps = torch.cat([torch.zeros((1, padding), dtype=torch.long), timesteps], dim=1)\n",
    "\n",
    "    state_preds, action_preds, return_preds = model.original_forward(\n",
    "        states=states,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        returns_to_go=returns_to_go,\n",
    "        timesteps=timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "        return_dict=False,\n",
    "    )\n",
    "\n",
    "    return action_preds[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eb59083-e711-4faa-802a-6d4c87443e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the environment\n",
    "\n",
    "name_load = 'li2p'\n",
    "version = '108'\n",
    "rseed = int(version)\n",
    "buffer_save_path = 'buffers_inf/'\n",
    "buffer_size = 5200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe01097-564c-49c9-ab40-df0689ad371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved_pars/{}_pars_cryoenv.pkl\".format(name_load),\"rb\") as fh:\n",
    "    pars_load = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05c006b-93ca-46de-b28d-9362d2a43fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryoenv.mqtt import augment_pars\n",
    "import gymnasium as gym\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e5be0d4-b216-4ff0-991b-5844236a6e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All transistions reachable, continuing\n"
     ]
    }
   ],
   "source": [
    "tries = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    if tries > 10:\n",
    "        raise AssertionError\n",
    "\n",
    "    add_pars = {\n",
    "        'store_raw': True,\n",
    "        'max_buffer_len': buffer_size,\n",
    "        'tpa_queue': [0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'pileup_prob': 0.,\n",
    "        'tp_interval': 10,\n",
    "        'dac_range': (0., 5.), \n",
    "        'Ib_range': (0.5, 5.), \n",
    "        'adc_range': (-10., 10.),\n",
    "        'rseed': rseed,\n",
    "        'tau_cap': np.array([1.]),\n",
    "                }\n",
    "\n",
    "    np.random.seed(rseed)\n",
    "\n",
    "    # pars_load = double_tes(pars_load)\n",
    "\n",
    "    aug_pars = augment_pars(pars_load, **add_pars)\n",
    "    # aug_pars = {**pars_load, **add_pars}\n",
    "\n",
    "    env = gym.make('cryoenv:cryoenv-sig-v0',\n",
    "                       omega=0.01,\n",
    "                       log_reward=False,\n",
    "                       rand_start=True,\n",
    "                       relax_time=60,\n",
    "                       tpa_in_state=True,\n",
    "                       div_adc_by_bias=True,\n",
    "                       pars=aug_pars,\n",
    "                       render_mode='plotly',\n",
    "                       rand_tpa=False,\n",
    "                       )\n",
    "\n",
    "    # check if transition is reachable\n",
    "\n",
    "    env.detector.set_control(dac=np.ones(env.nheater), Ib=np.ones(env.ntes), norm=True)\n",
    "\n",
    "    for i in range(10):\n",
    "        env.detector.wait(5)\n",
    "\n",
    "    try:\n",
    "        for i in range(env.ntes):  # assumes TES are the first components!\n",
    "            assert env.detector.Rt[i](env.detector.T[0,i]) > env.detector.Rs[i], 'transition of TES {} not reachable'.format(i)\n",
    "        print('All transistions reachable, continuing')\n",
    "        break\n",
    "    except AssertionError:\n",
    "        rseed *= 1000\n",
    "        tries += 1\n",
    "        print('Resampling parameters, new rseed: {}'.format(rseed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef933b54-8b56-4304-acd4-83deb5c1d849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aec44b1423345609514c9c36d0ce5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'yellow'},\n",
       "              'mode': 'lines',\n",
       "              'nameâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.launch_display(title='Inference {} with {} TES'.format(name_load, env.ntes), \n",
    "                   color='red' if name_load == 'li1p' else 'turquoise' if name_load == 'li1l' else 'yellow' if name_load == 'li2p' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62c3dce6-961e-41e1-8f18-c4a308273c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9973825  -0.99988246 -0.15172821 -0.37314853 -0.077825   -0.99470603]\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "scale = 60.  # 1000.0  # normalization for rewards/returns\n",
    "TARGET_RETURN = -3. # / scale  # 12000 / scale  # evaluation is conditioned on a return of 12000, scaled accordingly\n",
    "\n",
    "state_mean = collator.state_mean.astype(np.float32)\n",
    "state_std = collator.state_std.astype(np.float32)\n",
    "print(state_mean)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "# Create the decision transformer model\n",
    "\n",
    "state_mean = torch.from_numpy(state_mean).to(device=device)\n",
    "state_std = torch.from_numpy(state_std).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b5e7b90-fff9-4041-9681-fa9076fcda2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:197: DeprecationWarning:\n",
      "\n",
      "\u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "\n",
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:210: DeprecationWarning:\n",
      "\n",
      "\u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "\n",
      "/users/felix.wagner/.local/lib/python3.9/site-packages/scipy/integrate/_odepack_py.py:248: ODEintWarning:\n",
      "\n",
      "Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "\n",
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "\n",
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8370d30712c147958a36fba5d290ede4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "\n",
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "episode_return, episode_length = 0, 0\n",
    "\n",
    "state, _ = env.reset(clear_buffer=True)\n",
    "\n",
    "target_return = torch.tensor(TARGET_RETURN, device=device, dtype=torch.float32).reshape(1, 1)\n",
    "states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "actions = torch.zeros((0, act_dim), device=device, dtype=torch.float32)\n",
    "rewards = torch.zeros(0, device=device, dtype=torch.float32)\n",
    "\n",
    "timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n",
    "for t in trange(60):\n",
    "    actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
    "    rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n",
    "    \n",
    "    action = get_action(\n",
    "        model,\n",
    "        (states - state_mean) / state_std,\n",
    "        actions,\n",
    "        rewards,\n",
    "        target_return,\n",
    "        timesteps,\n",
    "    )\n",
    "    actions[-1] = action\n",
    "    action = action.detach().cpu().numpy()\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    \n",
    "    # print(action, state, reward)\n",
    "    \n",
    "    cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n",
    "    states = torch.cat([states, cur_state], dim=0)\n",
    "    rewards[-1] = reward\n",
    "\n",
    "    pred_return = target_return[0, -1] - (reward / scale)\n",
    "    target_return = torch.cat([target_return, pred_return.reshape(1, 1)], dim=1)\n",
    "    timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (t + 1)], dim=1)\n",
    "\n",
    "    episode_return += reward\n",
    "    episode_length += 1\n",
    "\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b218987-bd82-49f8-ba39-d01a935655f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
