{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fc72d-9816-4c4e-a98d-f5ae795a1d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import DecisionTransformerConfig, DecisionTransformerModel, Trainer, TrainingArguments\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13632fb2-d198-4e8e-9b4f-6e7d2b7ebd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shuffle = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4543ed84-5fe1-44bf-ae56-3e5ed4ae7343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset pandas (/users/felix.wagner/.cache/huggingface/datasets/pandas/default-c46fa57facf0c0a8/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a654560fc842d99b03220ce3de5848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset pandas (/users/felix.wagner/.cache/huggingface/datasets/pandas/default-b8ae2cee5f5334cb/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515f75282f754215ae1027e25eaa3edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset pandas (/users/felix.wagner/.cache/huggingface/datasets/pandas/default-03cc66ec0e07b29e/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d72fa8c73f40fcab4b49f4384dd01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train = load_dataset(\"pandas\", data_files=\"saved_pars/transformer_dataset_train.pkl\")['train']\n",
    "dataset_validation = load_dataset(\"pandas\", data_files=\"saved_pars/transformer_dataset_validation.pkl\")['train']\n",
    "dataset_test = load_dataset(\"pandas\", data_files=\"saved_pars/transformer_dataset_test.pkl\")['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095068a6-8638-46ef-8566-2a4a6d833104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /users/felix.wagner/.cache/huggingface/datasets/pandas/default-c46fa57facf0c0a8/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202/cache-8e4dad88354124b7.arrow\n",
      "Loading cached shuffled indices for dataset at /users/felix.wagner/.cache/huggingface/datasets/pandas/default-b8ae2cee5f5334cb/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202/cache-353a862696a81e70.arrow\n",
      "Loading cached shuffled indices for dataset at /users/felix.wagner/.cache/huggingface/datasets/pandas/default-03cc66ec0e07b29e/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202/cache-d8c5bebe3a48367f.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_train.shuffle(42)\n",
    "dataset_validation = dataset_validation.shuffle(42)\n",
    "dataset_test = dataset_test.shuffle(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919a8137-134b-4b82-bfa0-d7218af0f704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecisionTransformerGymDataCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "    max_len: int = 60 #subsets of the episode we use for training\n",
    "    state_dim: int = 6  # size of state space\n",
    "    act_dim: int = 2  # size of action space\n",
    "    max_ep_len: int = 60 # max episode length in the dataset\n",
    "    scale: float = 10.0  # normalization of rewards/returns\n",
    "    target: float = 0.  # highest return in training set\n",
    "    state_mean: np.array = None  # to store state means\n",
    "    state_std: np.array = None  # to store state stds\n",
    "    p_sample: np.array = None  # a distribution to take account trajectory lengths\n",
    "    n_traj: int = 0 # to store the number of trajectories in the dataset\n",
    "\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.act_dim = len(dataset[0][\"actions\"][0])\n",
    "        self.state_dim = len(dataset[0][\"observations\"][0])\n",
    "        self.dataset = dataset\n",
    "        # calculate dataset stats for normalization of states\n",
    "        states = []\n",
    "        rewards = []\n",
    "        traj_lens = []\n",
    "        for obs, rew in zip(dataset[\"observations\"], dataset[\"rewards\"]):\n",
    "            states.extend(obs)\n",
    "            rewards.append(rew)\n",
    "            traj_lens.append(len(obs))\n",
    "        self.n_traj = len(traj_lens)\n",
    "        states = np.vstack(states)\n",
    "        rewards = np.array(rewards)\n",
    "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "        \n",
    "        self.scale, self.target = np.abs(np.mean(np.sum(rewards, axis=1))), np.max(np.sum(rewards, axis=1))\n",
    "        # this assumes all rewards have same sign\n",
    "        \n",
    "        traj_lens = np.array(traj_lens)\n",
    "        self.p_sample = traj_lens / sum(traj_lens)\n",
    "\n",
    "    def _discount_cumsum(self, x, gamma):\n",
    "        discount_cumsum = np.zeros_like(x)\n",
    "        discount_cumsum[-1] = x[-1]\n",
    "        for t in reversed(range(x.shape[0] - 1)):\n",
    "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "        return discount_cumsum\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch_size = len(features)\n",
    "        # this is a bit of a hack to be able to sample of a non-uniform distribution\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(self.n_traj),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=self.p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "        # a batch of dataset features\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "        \n",
    "        for ind in batch_inds:\n",
    "            # for feature in features:\n",
    "            feature = self.dataset[int(ind)]\n",
    "            si = random.randint(0, len(feature[\"rewards\"]) - 1)\n",
    "\n",
    "            # get sequences from dataset\n",
    "            s.append(np.array(feature[\"observations\"][si : si + self.max_len]).reshape(1, -1, self.state_dim))\n",
    "            a.append(np.array(feature[\"actions\"][si : si + self.max_len]).reshape(1, -1, self.act_dim))\n",
    "            r.append(np.array(feature[\"rewards\"][si : si + self.max_len]).reshape(1, -1, 1))\n",
    "\n",
    "            d.append(np.array(feature[\"dones\"][si : si + self.max_len]).reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= self.max_ep_len] = self.max_ep_len - 1  # padding cutoff\n",
    "            rtg.append(\n",
    "                self._discount_cumsum(np.array(feature[\"rewards\"][si:]), gamma=1.0)[\n",
    "                    : s[-1].shape[1]   # TODO check the +1 removed here\n",
    "                ].reshape(1, -1, 1)\n",
    "            )\n",
    "            if rtg[-1].shape[1] < s[-1].shape[1]:\n",
    "                print(\"if true\")\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, self.state_dim)), s[-1]], axis=1)\n",
    "            s[-1] = (s[-1] - self.state_mean) / self.state_std\n",
    "            a[-1] = np.concatenate(\n",
    "                [np.ones((1, self.max_len - tlen, self.act_dim)) * -10.0, a[-1]],\n",
    "                axis=1,\n",
    "            )\n",
    "            r[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, self.max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), rtg[-1]], axis=1) / self.scale\n",
    "            timesteps[-1] = np.concatenate([np.zeros((1, self.max_len - tlen)), timesteps[-1]], axis=1)\n",
    "            mask.append(np.concatenate([np.zeros((1, self.max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).float()\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).float()\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).float()\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0))\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).float()\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).long()\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).float()\n",
    "\n",
    "        return {\n",
    "            \"states\": s,\n",
    "            \"actions\": a,\n",
    "            \"rewards\": r,\n",
    "\n",
    "            \"returns_to_go\": rtg,\n",
    "            \"timesteps\": timesteps,\n",
    "            \"attention_mask\": mask,\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315e2ba5-0900-40c3-9068-6b09f7af72fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainableDT(DecisionTransformerModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        output = super().forward(**kwargs)\n",
    "        # add the DT loss\n",
    "        action_preds = output[1]\n",
    "        action_targets = kwargs[\"actions\"]\n",
    "        attention_mask = kwargs[\"attention_mask\"]\n",
    "        act_dim = action_preds.shape[2]\n",
    "        action_preds = action_preds.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        action_targets = action_targets.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        \n",
    "        loss = torch.mean((action_preds - action_targets) ** 2)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def original_forward(self, **kwargs):\n",
    "        return super().forward(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d94f85-04e7-4853-9f11-b1e31570d428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collator = DecisionTransformerGymDataCollator(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a42141-d033-4ad7-9067-c7247a2fd9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = DecisionTransformerConfig(state_dim=collator.state_dim, \n",
    "                                   act_dim=collator.act_dim, \n",
    "                                   hidden_size=512,  # default 128, 10M 512, 40M 768, 200M 1280\n",
    "                                   n_layer=4,  # default 3, 10M 4, 40M 6, 200M 10\n",
    "                                   n_head=8,  # default 1, 10M 8, 40M 12, 200M 20\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb3a053-8932-4226-b3bc-9e308fe1be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TrainableDT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9074864-c141-465c-b194-cebbcb332f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TrainableDT.from_pretrained('/scratch-cbe/users/felix.wagner/rltests/output_40m/run1_checkpoint-56500')  # 40 M\n",
    "\n",
    "model = TrainableDT.from_pretrained('/scratch-cbe/users/felix.wagner/rltests/output/checkpoint-90000')  # 10 M\n",
    "\n",
    "# model = TrainableDT.from_pretrained('output/run1_checkpoint-47500/')  # 1 M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3290e865-0019-4310-960f-33a2a411bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(  # defaults from multiagent DT paper \n",
    "    output_dir=\"/scratch-cbe/users/felix.wagner/rltests/output/\",\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=3000,\n",
    "    per_device_train_batch_size=256,  # 64\n",
    "    learning_rate=3e-4,  # 1e-4\n",
    "    weight_decay=0.,  # 1e-4\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=1.,  # 0.25\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    label_names=[\"actions\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    data_collator=collator,\n",
    "    eval_dataset=dataset_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2538c00-e8ca-48a0-bc7e-398c764e6adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0009194285375997424, 'test_runtime': 7.4022, 'test_samples_per_second': 340.438, 'test_steps_per_second': 42.555}\n",
      "{'test_loss': 0.0009071200620383024, 'test_runtime': 7.1806, 'test_samples_per_second': 350.944, 'test_steps_per_second': 43.868}\n"
     ]
    }
   ],
   "source": [
    "preds_test = trainer.predict(dataset_test)\n",
    "preds_val = trainer.predict(dataset_validation)\n",
    "print(preds_test.metrics)\n",
    "print(preds_val.metrics)\n",
    "\n",
    "# for wrong dataset loss was ~ 0.004 (50k steps)\n",
    "\n",
    "# for correct data set (50k steps)\n",
    "\n",
    "# test 0.10790583491325378\n",
    "# validation 0.10896196961402893\n",
    "\n",
    "# for correct data set 10M model (47.5k steps)\n",
    "\n",
    "# test 0.05410\n",
    "# validation 0.05418\n",
    "\n",
    "# for correct data set 10M model (178.5k steps)\n",
    "\n",
    "# test 0.01736\n",
    "# validation 0.01809\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4cbf33-9a6d-4fb9-90c5-bdfe6c8bf3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ea78cd64224ef99df0a5dca20af586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='83182' max='90000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [83182/90000 32:31 < 2:12:00, 0.86 it/s, Epoch 2772.70/3000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train('/scratch-cbe/users/felix.wagner/rltests/output/checkpoint-90000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4080f-ee57-4ab7-a149-62f1a8839974",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca9e273-de2f-47c3-bb63-d8449a230cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets an action from the model using autoregressive prediction with a window of the previous 20 timesteps.\n",
    "def get_action(model, states, actions, rewards, returns_to_go, timesteps):\n",
    "    # This implementation does not condition on past rewards\n",
    "\n",
    "    states = states.reshape(1, -1, model.config.state_dim)\n",
    "    actions = actions.reshape(1, -1, model.config.act_dim)\n",
    "    returns_to_go = returns_to_go.reshape(1, -1, 1)\n",
    "    timesteps = timesteps.reshape(1, -1)\n",
    "\n",
    "    states = states[:, -model.config.max_length :]\n",
    "    actions = actions[:, -model.config.max_length :]\n",
    "    returns_to_go = returns_to_go[:, -model.config.max_length :]\n",
    "    timesteps = timesteps[:, -model.config.max_length :]\n",
    "    padding = model.config.max_length - states.shape[1]\n",
    "    # pad all tokens to sequence length\n",
    "    attention_mask = torch.cat([torch.zeros(padding), torch.ones(states.shape[1])])\n",
    "    attention_mask = attention_mask.to(dtype=torch.long).reshape(1, -1)\n",
    "    states = torch.cat([torch.zeros((1, padding, model.config.state_dim)), states], dim=1).float()\n",
    "    actions = torch.cat([torch.zeros((1, padding, model.config.act_dim)), actions], dim=1).float()\n",
    "    returns_to_go = torch.cat([torch.zeros((1, padding, 1)), returns_to_go], dim=1).float()\n",
    "    timesteps = torch.cat([torch.zeros((1, padding), dtype=torch.long), timesteps], dim=1)\n",
    "\n",
    "    state_preds, action_preds, return_preds = model.original_forward(\n",
    "        states=states,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        returns_to_go=returns_to_go,\n",
    "        timesteps=timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "        return_dict=False,\n",
    "    )\n",
    "\n",
    "    return action_preds[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c939e5f-04b0-43ca-ae68-fed22218e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thats crucial!\n",
    "\n",
    "model.config.max_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7eb59083-e711-4faa-802a-6d4c87443e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the environment\n",
    "\n",
    "name_load = 'li2p'\n",
    "version = '24'\n",
    "rseed = int(version)\n",
    "buffer_save_path = 'buffers_inf/'\n",
    "buffer_size = 5200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bbe01097-564c-49c9-ab40-df0689ad371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved_pars/{}_pars_cryoenv.pkl\".format(name_load),\"rb\") as fh:\n",
    "    pars_load = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d05c006b-93ca-46de-b28d-9362d2a43fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryoenv.mqtt import augment_pars\n",
    "import gymnasium as gym\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e5be0d4-b216-4ff0-991b-5844236a6e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All transistions reachable, continuing\n"
     ]
    }
   ],
   "source": [
    "tries = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    if tries > 10:\n",
    "        raise AssertionError\n",
    "\n",
    "    add_pars = {\n",
    "        'store_raw': True,\n",
    "        'max_buffer_len': buffer_size,\n",
    "        'tpa_queue': [0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'pileup_prob': 0.,\n",
    "        'tp_interval': 10,\n",
    "        'dac_range': (0., 5.) if name_load in ['li1p', 'li2p'] else (0., 10.),  # this was changed\n",
    "        'Ib_range': (0.5, 5.) if name_load in ['li1p', 'li2p'] else (0.1, 3.),  # this was changed\n",
    "        'adc_range': (-10., 10.),\n",
    "        'rseed': rseed,\n",
    "        'tau_cap': np.array([1.]),\n",
    "                }\n",
    "\n",
    "    np.random.seed(rseed)\n",
    "\n",
    "    # pars_load = double_tes(pars_load)\n",
    "\n",
    "    aug_pars = augment_pars(pars_load, **add_pars)\n",
    "    # aug_pars = {**pars_load, **add_pars}\n",
    "\n",
    "    env = gym.make('cryoenv:cryoenv-sig-v0',\n",
    "                       omega=0.,\n",
    "                       log_reward=False,\n",
    "                       rand_start=True,\n",
    "                       relax_time=60,\n",
    "                       tpa_in_state=True,\n",
    "                       div_adc_by_bias=True,\n",
    "                       pars=aug_pars,\n",
    "                       render_mode='plotly',\n",
    "                       rand_tpa=False,\n",
    "                       )\n",
    "\n",
    "    # check if transition is reachable\n",
    "\n",
    "    env.detector.set_control(dac=np.ones(env.nheater), Ib=np.ones(env.ntes), norm=True)\n",
    "\n",
    "    for i in range(10):\n",
    "        env.detector.wait(5)\n",
    "\n",
    "    try:\n",
    "        for i in range(env.ntes):  # assumes TES are the first components!\n",
    "            assert env.detector.Rt[i](env.detector.T[0,i]) > env.detector.Rs[i], 'transition of TES {} not reachable'.format(i)\n",
    "        print('All transistions reachable, continuing')\n",
    "        break\n",
    "    except AssertionError:\n",
    "        rseed *= 1000\n",
    "        tries += 1\n",
    "        print('Resampling parameters, new rseed: {}'.format(rseed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ef933b54-8b56-4304-acd4-83deb5c1d849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06e87aa29f74a6c98cf013e3d35907a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'yellow'},\n",
       "              'mode': 'lines',\n",
       "              'name…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.launch_display(title='Inference {} with {} TES'.format(name_load, env.ntes), \n",
    "                   color='red' if name_load == 'li1p' else 'turquoise' if name_load == 'li1l' else 'yellow' if name_load == 'li2p' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62c3dce6-961e-41e1-8f18-c4a308273c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.28086632379302 -2.865846695672037\n",
      "[-0.99449515 -0.9999367  -0.0147091  -0.12026685 -0.07332222 -0.98970175]\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "scale = collator.scale # 1000.0  # normalization for rewards/returns\n",
    "TARGET_EXPLORE = -0.3\n",
    "TARGET_EXPLOIT = -0.024 if name_load == 'li1p' else -0.08 if name_load == 'li1p' else -0.02 \n",
    "TARGET_RETURN = TARGET_EXPLORE * 60 / scale  # collator.target # / scale  # 12000 / scale  # evaluation is conditioned on a return of 12000, scaled accordingly\n",
    "print(scale, TARGET_RETURN)\n",
    "\n",
    "state_mean = collator.state_mean.astype(np.float32)\n",
    "state_std = collator.state_std.astype(np.float32)\n",
    "print(state_mean)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "\n",
    "state_mean = torch.from_numpy(state_mean).to(device=device)\n",
    "state_std = torch.from_numpy(state_std).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0b5e7b90-fff9-4041-9681-fa9076fcda2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRY 0/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e597028147487cb92c5bc86eb4602f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRY 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1e5d7bd3904923b21fbdc0ba7a047c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching in t=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/felix.wagner/cryoenv/cryoenv/cryosig/_detector_model.py:1199: RuntimeWarning:\n",
      "\n",
      "overflow encountered in double_scalars\n",
      "\n",
      "/users/felix.wagner/cryoenv/cryoenv/cryosig/_detector_model.py:1199: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/users/felix.wagner/.local/lib/python3.9/site-packages/scipy/integrate/_odepack_py.py:248: ODEintWarning:\n",
      "\n",
      "Excess accuracy requested (tolerances too small). Run with full_output = 1 to get quantitative information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRY 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/felix.wagner/cryoenv/cryoenv/cryosig/_detector_model.py:320: RuntimeWarning:\n",
      "\n",
      "overflow encountered in multiply\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c90b4713bf44eea375c0d8aeeec92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRY 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889dd6be020341fe8648452f38af72dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [128]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m actions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m action\n\u001b[1;32m     32\u001b[0m action \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 34\u001b[0m state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     38\u001b[0m cur_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(state)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, state_dim)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cryoenv/cryoenv/envs/_sigwrap.py:100\u001b[0m, in \u001b[0;36mCryoEnvSigWrapper.step\u001b[0;34m(self, action, alternative_order)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# new_state[3 * self.ntes + 2 * self.nheater:4 * self.ntes + 2 * self.nheater] = \\\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m#     self.state[3 * self.ntes + 2 * self.nheater:4 * self.ntes + 2 * self.nheater] * relax_factor - \\\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m#     (1 - relax_factor) * self.detector.get('Ib', norm=True)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# new_state[4 * self.ntes + 2 * self.nheater:4 * self.ntes + 3 * self.nheater] = \\\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m#     self.state[4 * self.ntes + 2 * self.nheater:4 * self.ntes + 3 * self.nheater] * relax_factor - \\\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m#     (1 - relax_factor) * self.detector.get('dac', norm=True)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotly\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# render before CP is sent\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43malternative_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malternative_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# attention, important that we take the reward here, otherwise we would calc it with the CPs\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_reward:\n",
      "File \u001b[0;32m~/cryoenv/cryoenv/envs/_sigwrap.py:228\u001b[0m, in \u001b[0;36mCryoEnvSigWrapper.render\u001b[0;34m(self, save_path, alternative_order)\u001b[0m\n\u001b[1;32m    226\u001b[0m buffer_Ib \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mbuffer_Ib)[flag]\n\u001b[1;32m    227\u001b[0m ib \u001b[38;5;241m=\u001b[39m buffer_Ib[idx_start::\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpulse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtes_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cryoenv/cryoenv/envs/_sigwrap.py:263\u001b[0m, in \u001b[0;36mCryoEnvSigWrapper.update_display\u001b[0;34m(self, pulse, ph, dac, ib, tes_channel)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m tes_channel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pulse\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m tes_channel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ph\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m tes_channel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dac\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m tes_channel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ib\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/plotly/basedatatypes.py:4824\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_invalid_property_error()(prop)\n\u001b[1;32m   4823\u001b[0m \u001b[38;5;66;03m# ### Get validator for this property ###\u001b[39;00m\n\u001b[0;32m-> 4824\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_validator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4826\u001b[0m \u001b[38;5;66;03m# ### Handle compound property ###\u001b[39;00m\n\u001b[1;32m   4827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(validator, CompoundValidator):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/plotly/basedatatypes.py:4306\u001b[0m, in \u001b[0;36mBasePlotlyType._get_validator\u001b[0;34m(self, prop)\u001b[0m\n\u001b[1;32m   4303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_validator\u001b[39m(\u001b[38;5;28mself\u001b[39m, prop):\n\u001b[1;32m   4304\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidator_cache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValidatorCache\n\u001b[0;32m-> 4306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mValidatorCache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_validator\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_str, prop)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tries = 10\n",
    "\n",
    "for try_ in range(tries):\n",
    "    \n",
    "    print('TRY {}/{}'.format(try_, tries))\n",
    "\n",
    "    episode_return, episode_length = 0, 0\n",
    "\n",
    "    state, _ = env.reset(clear_buffer=True)\n",
    "\n",
    "    target_return = torch.tensor(TARGET_RETURN, device=device, dtype=torch.float32).reshape(1, 1)\n",
    "    states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "    actions = torch.zeros((0, act_dim), device=device, dtype=torch.float32)\n",
    "    rewards = torch.zeros(0, device=device, dtype=torch.float32)\n",
    "\n",
    "    switched = False\n",
    "\n",
    "    timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n",
    "    for t in trange(60):\n",
    "        actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
    "        rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n",
    "\n",
    "        action = get_action(\n",
    "            model,\n",
    "            (states - state_mean) / state_std,\n",
    "            actions,\n",
    "            rewards,\n",
    "            target_return,\n",
    "            timesteps,\n",
    "        )\n",
    "        actions[-1] = action\n",
    "        action = action.detach().cpu().numpy()\n",
    "\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "\n",
    "        cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n",
    "        states = torch.cat([states, cur_state], dim=0)\n",
    "        rewards[-1] = reward\n",
    "\n",
    "        pred_return = target_return[0, -1] - (reward / scale)\n",
    "        target_return = torch.cat([target_return, pred_return.reshape(1, 1)], dim=1)\n",
    "\n",
    "\n",
    "        episode_return += reward\n",
    "        episode_length += 1\n",
    "\n",
    "        if reward > -0.15 and not switched:\n",
    "            target_return += (TARGET_EXPLOIT * 60 / scale - TARGET_RETURN) * (60-t)/60\n",
    "            print('Switching in t={}'.format(t))\n",
    "            switched = True\n",
    "\n",
    "        if target_return[0,-1] > (60-t)*TARGET_EXPLORE/scale/2 and not switched:\n",
    "            target_return[0, :] += (60-t)*(TARGET_EXPLORE/scale) - target_return[0, -1]\n",
    "        if target_return[0,-1] > (60-t)*TARGET_EXPLOIT/scale/2  and switched:\n",
    "            target_return[0, :] += (60-t)*(TARGET_EXPLORE/scale) - target_return[0, -1]\n",
    "            switched = False\n",
    "            print('Switching back in t={}'.format(t))\n",
    "\n",
    "        timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (t + 1)], dim=1)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "    if np.mean(-np.array(env.detector.buffer_rms[-30:])/np.array(env.detector.buffer_ph[-30:])) > 2 * TARGET_EXPLOIT:\n",
    "        print('SUCCESS')\n",
    "        break\n",
    "        \n",
    "    if try_ == tries - 1:\n",
    "        print('FAILED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b218987-bd82-49f8-ba39-d01a935655f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(-np.array(env.detector.buffer_rms[-30:])/np.array(env.detector.buffer_ph[-30:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22b6a378-92c0-43c6-b8fb-2ecc97a7c39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b8f3bac31f0>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(target_return.flatten())\n",
    "plt.plot(np.linspace(TARGET_EXPLORE * 60 / scale,0,60))\n",
    "plt.plot(np.linspace(TARGET_EXPLOIT * 60 / scale,0,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029371e-da52-47b1-995c-e1f7e116abd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb76391-f90e-4ab9-8c09-049df3bb0878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
