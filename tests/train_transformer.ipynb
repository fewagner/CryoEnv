{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7fc72d-9816-4c4e-a98d-f5ae795a1d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import DecisionTransformerConfig, DecisionTransformerModel, Trainer, TrainingArguments\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13632fb2-d198-4e8e-9b4f-6e7d2b7ebd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shuffle = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4543ed84-5fe1-44bf-ae56-3e5ed4ae7343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset pandas (/users/felix.wagner/.cache/huggingface/datasets/pandas/default-21302aee5d8248ec/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c58f81d4b374417b75daa45523d7d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset pandas (/users/felix.wagner/.cache/huggingface/datasets/pandas/default-30f0f8d230893acc/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77697cd8084d4132a0f6468390a9c13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset pandas (/users/felix.wagner/.cache/huggingface/datasets/pandas/default-58d62ae17baf694c/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae81690f3e164f22a98549f99f597bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train = load_dataset(\"pandas\", data_files=\"saved_pars/transformer_dataset_train.pkl\")['train']\n",
    "dataset_validation = load_dataset(\"pandas\", data_files=\"saved_pars/transformer_dataset_validation.pkl\")['train']\n",
    "dataset_test = load_dataset(\"pandas\", data_files=\"saved_pars/transformer_dataset_test.pkl\")['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095068a6-8638-46ef-8566-2a4a6d833104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /users/felix.wagner/.cache/huggingface/datasets/pandas/default-21302aee5d8248ec/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202/cache-54e05dbb326fed7a.arrow\n",
      "Loading cached shuffled indices for dataset at /users/felix.wagner/.cache/huggingface/datasets/pandas/default-30f0f8d230893acc/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202/cache-036f508fcefb23db.arrow\n",
      "Loading cached shuffled indices for dataset at /users/felix.wagner/.cache/huggingface/datasets/pandas/default-58d62ae17baf694c/0.0.0/3ac4ffc4563c796122ef66899b9485a3f1a977553e2d2a8a318c72b8cc6f2202/cache-6ef6ed4c2aa0074d.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_train.shuffle(42)\n",
    "dataset_validation = dataset_validation.shuffle(42)\n",
    "dataset_test = dataset_test.shuffle(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919a8137-134b-4b82-bfa0-d7218af0f704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecisionTransformerGymDataCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "    max_len: int = 20 #subsets of the episode we use for training\n",
    "    state_dim: int = 6  # size of state space\n",
    "    act_dim: int = 2  # size of action space\n",
    "    max_ep_len: int = 60 # max episode length in the dataset\n",
    "    scale: float = 10.0  # normalization of rewards/returns\n",
    "    target: float = 0.  # highest return in training set\n",
    "    state_mean: np.array = None  # to store state means\n",
    "    state_std: np.array = None  # to store state stds\n",
    "    p_sample: np.array = None  # a distribution to take account trajectory lengths\n",
    "    n_traj: int = 0 # to store the number of trajectories in the dataset\n",
    "\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.act_dim = len(dataset[0][\"actions\"][0])\n",
    "        self.state_dim = len(dataset[0][\"observations\"][0])\n",
    "        self.dataset = dataset\n",
    "        # calculate dataset stats for normalization of states\n",
    "        states = []\n",
    "        rewards = []\n",
    "        traj_lens = []\n",
    "        for obs, rew in zip(dataset[\"observations\"], dataset[\"rewards\"]):\n",
    "            states.extend(obs)\n",
    "            rewards.append(rew)\n",
    "            traj_lens.append(len(obs))\n",
    "        self.n_traj = len(traj_lens)\n",
    "        states = np.vstack(states)\n",
    "        rewards = np.array(rewards)\n",
    "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "        \n",
    "        self.scale, self.target = np.abs(np.mean(np.sum(rewards, axis=1))), np.max(np.sum(rewards, axis=1))\n",
    "        # this assumes all rewards have same sign\n",
    "        \n",
    "        traj_lens = np.array(traj_lens)\n",
    "        self.p_sample = traj_lens / sum(traj_lens)\n",
    "\n",
    "    def _discount_cumsum(self, x, gamma):\n",
    "        discount_cumsum = np.zeros_like(x)\n",
    "        discount_cumsum[-1] = x[-1]\n",
    "        for t in reversed(range(x.shape[0] - 1)):\n",
    "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "        return discount_cumsum\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch_size = len(features)\n",
    "        # this is a bit of a hack to be able to sample of a non-uniform distribution\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(self.n_traj),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=self.p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "        # a batch of dataset features\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "        \n",
    "        for ind in batch_inds:\n",
    "            # for feature in features:\n",
    "            feature = self.dataset[int(ind)]\n",
    "            si = random.randint(0, len(feature[\"rewards\"]) - 1)\n",
    "\n",
    "            # get sequences from dataset\n",
    "            s.append(np.array(feature[\"observations\"][si : si + self.max_len]).reshape(1, -1, self.state_dim))\n",
    "            a.append(np.array(feature[\"actions\"][si : si + self.max_len]).reshape(1, -1, self.act_dim))\n",
    "            r.append(np.array(feature[\"rewards\"][si : si + self.max_len]).reshape(1, -1, 1))\n",
    "\n",
    "            d.append(np.array(feature[\"dones\"][si : si + self.max_len]).reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= self.max_ep_len] = self.max_ep_len - 1  # padding cutoff\n",
    "            rtg.append(\n",
    "                self._discount_cumsum(np.array(feature[\"rewards\"][si:]), gamma=1.0)[\n",
    "                    : s[-1].shape[1]   # TODO check the +1 removed here\n",
    "                ].reshape(1, -1, 1)\n",
    "            )\n",
    "            if rtg[-1].shape[1] < s[-1].shape[1]:\n",
    "                print(\"if true\")\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, self.state_dim)), s[-1]], axis=1)\n",
    "            s[-1] = (s[-1] - self.state_mean) / self.state_std\n",
    "            a[-1] = np.concatenate(\n",
    "                [np.ones((1, self.max_len - tlen, self.act_dim)) * -10.0, a[-1]],\n",
    "                axis=1,\n",
    "            )\n",
    "            r[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, self.max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), rtg[-1]], axis=1) / self.scale\n",
    "            timesteps[-1] = np.concatenate([np.zeros((1, self.max_len - tlen)), timesteps[-1]], axis=1)\n",
    "            mask.append(np.concatenate([np.zeros((1, self.max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).float()\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).float()\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).float()\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0))\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).float()\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).long()\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).float()\n",
    "\n",
    "        return {\n",
    "            \"states\": s,\n",
    "            \"actions\": a,\n",
    "            \"rewards\": r,\n",
    "\n",
    "            \"returns_to_go\": rtg,\n",
    "            \"timesteps\": timesteps,\n",
    "            \"attention_mask\": mask,\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315e2ba5-0900-40c3-9068-6b09f7af72fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainableDT(DecisionTransformerModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        output = super().forward(**kwargs)\n",
    "        # add the DT loss\n",
    "        action_preds = output[1]\n",
    "        action_targets = kwargs[\"actions\"]\n",
    "        attention_mask = kwargs[\"attention_mask\"]\n",
    "        act_dim = action_preds.shape[2]\n",
    "        action_preds = action_preds.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        action_targets = action_targets.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        \n",
    "        loss = torch.mean((action_preds - action_targets) ** 2)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def original_forward(self, **kwargs):\n",
    "        return super().forward(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d94f85-04e7-4853-9f11-b1e31570d428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collator = DecisionTransformerGymDataCollator(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a42141-d033-4ad7-9067-c7247a2fd9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = DecisionTransformerConfig(state_dim=collator.state_dim, \n",
    "                                   act_dim=collator.act_dim, \n",
    "                                   hidden_size=512,  # default 128, 10M 512, 40M 768, 200M 1280\n",
    "                                   n_layer=4,  # default 3, 10M 4, 40M 6, 200M 10\n",
    "                                   n_head=8,  # default 1, 10M 8, 40M 12, 200M 20\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb3a053-8932-4226-b3bc-9e308fe1be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TrainableDT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9074864-c141-465c-b194-cebbcb332f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TrainableDT.from_pretrained('/scratch-cbe/users/felix.wagner/rltests/output_40m/run1_checkpoint-56500')  # 40 M\n",
    "\n",
    "# model = TrainableDT.from_pretrained('output/run3_checkpoint-297500')  # 10 M\n",
    "\n",
    "model = TrainableDT.from_pretrained('output/run1_checkpoint-47500/')  # 1 M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3290e865-0019-4310-960f-33a2a411bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(  # defaults from DT paper \n",
    "    output_dir=\"output/\",\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=2500,\n",
    "    per_device_train_batch_size=64,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=0.25,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    label_names=[\"actions\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    data_collator=collator,\n",
    "    eval_dataset=dataset_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2538c00-e8ca-48a0-bc7e-398c764e6adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.10847790539264679, 'test_runtime': 8.3272, 'test_samples_per_second': 302.624, 'test_steps_per_second': 37.828}\n",
      "{'test_loss': 0.11001846194267273, 'test_runtime': 8.0447, 'test_samples_per_second': 313.251, 'test_steps_per_second': 39.156}\n"
     ]
    }
   ],
   "source": [
    "preds_test = trainer.predict(dataset_test)\n",
    "preds_val = trainer.predict(dataset_validation)\n",
    "print(preds_test.metrics)\n",
    "print(preds_val.metrics)\n",
    "\n",
    "# for wrong dataset loss was ~ 0.004 (50k steps)\n",
    "\n",
    "# for correct data set (50k steps)\n",
    "\n",
    "# test 0.10790583491325378\n",
    "# validation 0.10896196961402893\n",
    "\n",
    "# for correct data set 10M model (47.5k steps)\n",
    "\n",
    "# test 0.05410\n",
    "# validation 0.05418\n",
    "\n",
    "# for correct data set 10M model (178.5k steps)\n",
    "\n",
    "# test 0.01736\n",
    "# validation 0.01809\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4cbf33-9a6d-4fb9-90c5-bdfe6c8bf3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af1f1aaa8974ef6989e39c910d94057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155748' max='297500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [155748/297500 25:06 < 7:11:41, 5.47 it/s, Epoch 1308.80/2500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>148000</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.021080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148500</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.020775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.021662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149500</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.021030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.021230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150500</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.021663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.021352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151500</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152000</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.021541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152500</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.021387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153000</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.020987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153500</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.021267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154000</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154500</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.021719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.020836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155500</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.020761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train('output/run3_checkpoint-147500')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4080f-ee57-4ab7-a149-62f1a8839974",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca9e273-de2f-47c3-bb63-d8449a230cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets an action from the model using autoregressive prediction with a window of the previous 20 timesteps.\n",
    "def get_action(model, states, actions, rewards, returns_to_go, timesteps):\n",
    "    # This implementation does not condition on past rewards\n",
    "\n",
    "    states = states.reshape(1, -1, model.config.state_dim)\n",
    "    actions = actions.reshape(1, -1, model.config.act_dim)\n",
    "    returns_to_go = returns_to_go.reshape(1, -1, 1)\n",
    "    timesteps = timesteps.reshape(1, -1)\n",
    "\n",
    "    states = states[:, -model.config.max_length :]\n",
    "    actions = actions[:, -model.config.max_length :]\n",
    "    returns_to_go = returns_to_go[:, -model.config.max_length :]\n",
    "    timesteps = timesteps[:, -model.config.max_length :]\n",
    "    padding = model.config.max_length - states.shape[1]\n",
    "    # pad all tokens to sequence length\n",
    "    attention_mask = torch.cat([torch.zeros(padding), torch.ones(states.shape[1])])\n",
    "    attention_mask = attention_mask.to(dtype=torch.long).reshape(1, -1)\n",
    "    states = torch.cat([torch.zeros((1, padding, model.config.state_dim)), states], dim=1).float()\n",
    "    actions = torch.cat([torch.zeros((1, padding, model.config.act_dim)), actions], dim=1).float()\n",
    "    returns_to_go = torch.cat([torch.zeros((1, padding, 1)), returns_to_go], dim=1).float()\n",
    "    timesteps = torch.cat([torch.zeros((1, padding), dtype=torch.long), timesteps], dim=1)\n",
    "\n",
    "    state_preds, action_preds, return_preds = model.original_forward(\n",
    "        states=states,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        returns_to_go=returns_to_go,\n",
    "        timesteps=timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "        return_dict=False,\n",
    "    )\n",
    "\n",
    "    return action_preds[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c939e5f-04b0-43ca-ae68-fed22218e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thats crucial!\n",
    "\n",
    "model.config.max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eb59083-e711-4faa-802a-6d4c87443e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the environment\n",
    "\n",
    "name_load = 'li1l'\n",
    "version = '0'\n",
    "rseed = int(version)\n",
    "buffer_save_path = 'buffers_inf/'\n",
    "buffer_size = 5200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbe01097-564c-49c9-ab40-df0689ad371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved_pars/{}_pars_cryoenv.pkl\".format(name_load),\"rb\") as fh:\n",
    "    pars_load = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d05c006b-93ca-46de-b28d-9362d2a43fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryoenv.mqtt import augment_pars\n",
    "import gymnasium as gym\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e5be0d4-b216-4ff0-991b-5844236a6e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/felix.wagner/.local/lib/python3.9/site-packages/gymnasium/spaces/box.py:130: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All transistions reachable, continuing\n"
     ]
    }
   ],
   "source": [
    "tries = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    if tries > 10:\n",
    "        raise AssertionError\n",
    "\n",
    "    add_pars = {\n",
    "        'store_raw': True,\n",
    "        'max_buffer_len': buffer_size,\n",
    "        'tpa_queue': [0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'pileup_prob': 0.,\n",
    "        'tp_interval': 10,\n",
    "        'dac_range': (0., 5.), \n",
    "        'Ib_range': (0.5, 5.), \n",
    "        'adc_range': (-10., 10.),\n",
    "        'rseed': rseed,\n",
    "        'tau_cap': np.array([1.]),\n",
    "                }\n",
    "\n",
    "    np.random.seed(rseed)\n",
    "\n",
    "    # pars_load = double_tes(pars_load)\n",
    "\n",
    "    aug_pars = augment_pars(pars_load, **add_pars)\n",
    "    # aug_pars = {**pars_load, **add_pars}\n",
    "\n",
    "    env = gym.make('cryoenv:cryoenv-sig-v0',\n",
    "                       omega=0.01,\n",
    "                       log_reward=False,\n",
    "                       rand_start=True,\n",
    "                       relax_time=60,\n",
    "                       tpa_in_state=True,\n",
    "                       div_adc_by_bias=True,\n",
    "                       pars=aug_pars,\n",
    "                       render_mode='plotly',\n",
    "                       rand_tpa=False,\n",
    "                       )\n",
    "\n",
    "    # check if transition is reachable\n",
    "\n",
    "    env.detector.set_control(dac=np.ones(env.nheater), Ib=np.ones(env.ntes), norm=True)\n",
    "\n",
    "    for i in range(10):\n",
    "        env.detector.wait(5)\n",
    "\n",
    "    try:\n",
    "        for i in range(env.ntes):  # assumes TES are the first components!\n",
    "            assert env.detector.Rt[i](env.detector.T[0,i]) > env.detector.Rs[i], 'transition of TES {} not reachable'.format(i)\n",
    "        print('All transistions reachable, continuing')\n",
    "        break\n",
    "    except AssertionError:\n",
    "        rseed *= 1000\n",
    "        tries += 1\n",
    "        print('Resampling parameters, new rseed: {}'.format(rseed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef933b54-8b56-4304-acd4-83deb5c1d849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43bf58ad555431b8760997f55550a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'turquoise'},\n",
       "              'mode': 'lines',\n",
       "              'n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.launch_display(title='Inference {} with {} TES'.format(name_load, env.ntes), \n",
    "                   color='red' if name_load == 'li1p' else 'turquoise' if name_load == 'li1l' else 'yellow' if name_load == 'li2p' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62c3dce6-961e-41e1-8f18-c4a308273c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.050105657085041 0.0\n",
      "[-0.9962169  -0.99987376 -0.13282296 -0.13883239 -0.07098205 -0.9930848 ]\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "scale = collator.scale # 1000.0  # normalization for rewards/returns\n",
    "TARGET_RETURN = 0.  # collator.target # / scale  # 12000 / scale  # evaluation is conditioned on a return of 12000, scaled accordingly\n",
    "print(scale, TARGET_RETURN)\n",
    "\n",
    "state_mean = collator.state_mean.astype(np.float32)\n",
    "state_std = collator.state_std.astype(np.float32)\n",
    "print(state_mean)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "# Create the decision transformer model\n",
    "\n",
    "state_mean = torch.from_numpy(state_mean).to(device=device)\n",
    "state_std = torch.from_numpy(state_std).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b5e7b90-fff9-4041-9681-fa9076fcda2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfe5956d99b4562b3c2c5160f0bc09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_return, episode_length = 0, 0\n",
    "\n",
    "state, _ = env.reset(clear_buffer=True)\n",
    "\n",
    "target_return = torch.tensor(TARGET_RETURN, device=device, dtype=torch.float32).reshape(1, 1)\n",
    "states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "actions = torch.zeros((0, act_dim), device=device, dtype=torch.float32)\n",
    "rewards = torch.zeros(0, device=device, dtype=torch.float32)\n",
    "\n",
    "timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n",
    "for t in trange(60):\n",
    "    actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
    "    rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n",
    "    \n",
    "    action = get_action(\n",
    "        model,\n",
    "        (states - state_mean) / state_std,\n",
    "        actions,\n",
    "        rewards,\n",
    "        target_return,\n",
    "        timesteps,\n",
    "    )\n",
    "    actions[-1] = action\n",
    "    action = action.detach().cpu().numpy()\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    \n",
    "    # print(action, state, reward)\n",
    "    \n",
    "    cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n",
    "    states = torch.cat([states, cur_state], dim=0)\n",
    "    rewards[-1] = reward\n",
    "\n",
    "    pred_return = target_return[0, -1] - (reward / scale)\n",
    "    target_return = torch.cat([target_return, pred_return.reshape(1, 1)], dim=1)\n",
    "    timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (t + 1)], dim=1)\n",
    "\n",
    "    episode_return += reward\n",
    "    episode_length += 1\n",
    "\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b218987-bd82-49f8-ba39-d01a935655f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
